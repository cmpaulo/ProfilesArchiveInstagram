name: scraper-instagram_bot

on:
  [push]
  # schedule:
  #   - cron: '0 */12 * * *' # runs at each 12:00 everyday

jobs:
  build:
    runs-on: ubuntu-latest
    steps:

      - name: checkout repo content
        uses: actions/checkout@v2 # check
      
      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8.10' # install the python version needed  
      
      - name: download and install chrome browser
        run: |
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo apt install ./google-chrome-stable_current_amd64.deb

      - name: install python packages
        run: |
          python -m pip install --upgrade pip
          pip install -r requeriments.txt

          
      - name: execute py script to scrap # scrap profiles
        env: 
          EMAIL_ADDRESS: ${{ secrets.EMAIL_ADDRESS }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_RECIPIENT: ${{ secrets.EMAIL_RECIPIENT }}
          Usuario: ${{secrets.USUARIO}}
          Senha: ${{secrets.SENHA_SECRETA}}

        run: python WebscrapingInstagram_wkflw_test.py
      
      - name: commit files
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -A
          git commit -m "update data" -a
          
      - name: push changes
        uses: ad-m/github-push-action@v0.6.0
        with:
          branch: main  
          github_token: ${{ secrets.SECRET_TOKEN }}